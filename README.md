# ğŸ¦ Origaker: Adaptive Metamorphic Legged Robot Locomotion

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyBullet](https://img.shields.io/badge/PyBullet-3.2.5-green.svg)](https://pybullet.org/)
[![Stable-Baselines3](https://img.shields.io/badge/SB3-2.0+-orange.svg)](https://stable-baselines3.readthedocs.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Paper](https://img.shields.io/badge/Paper-MSc_Thesis-red.svg)](link-to-paper)
[![King's College London](https://img.shields.io/badge/Institution-King's_College_London-blue.svg)](https://www.kcl.ac.uk/)

> **Enhancing Metamorphic Legged Robot Locomotion Using Machine Learning and Nature-Inspired Design**

*MSc Robotics Individual Project | King's College London | August 2025*

<p align="center">
  <img src="assets/origaker_hero.gif" alt="Origaker in action" width="800"/>
</p>

---

## ğŸ“‹ Table of Contents

- [Project Motivation](#-project-motivation)
- [Key Features](#-key-features)
- [System Architecture](#-system-architecture)
- [Simulation Environment](#-simulation-environment)
- [Hybrid CPG Architecture](#-hybrid-cpg-architecture)
- [Reinforcement Learning Framework](#-reinforcement-learning-framework)
- [SLAM & Planning Pipeline](#-slam--planning-pipeline)
- [Morphology Reconfiguration](#-morphology-reconfiguration)
- [Results](#-results)
- [Demonstrations](#-demonstrations)
- [Installation](#-installation)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [Citation](#-citation)
- [Future Work](#-future-work)
- [Acknowledgements](#-acknowledgements)
- [License](#-license)

---

## ğŸ¯ Project Motivation

### The Problem

Metamorphic robots promise superior adaptability through physical reconfiguration, yet current systems face critical limitations:

<p align="center">
  <img src="assets/figures/origaker_robot.png" alt="Origaker Robot" width="600"/>
  <br>
  <em>Figure 1: The Origaker metamorphic quadruped robot platform</em>
</p>

#### **Current Limitations:**

1. **Fixed Gaits**: Pre-scripted locomotion patterns cannot adapt to dynamic terrain variations
2. **No Perception**: Lack of real-time environmental awareness and mapping capabilities
3. **No Morphological Autonomy**: Manual transitions between body configurations
4. **Dynamic Terrain Failures**: High failure rates on unstructured surfaces
5. **Limited Real-World Deployment**: Poor generalization beyond training conditions

#### **Real-World Impact:**

<table>
<tr>
<td width="50%">
<img src="assets/figures/fukushima_failure.jpg" alt="Fukushima Robot" width="100%"/>
<p align="center"><em><b>2011 Fukushima Disaster</b></em><br>Ground robots immobilized by debris due to morphology rigidity [Murphy et al., 2016]</p>
</td>
<td width="50%">
<img src="assets/figures/exomars_rover.png" alt="ExoMars Rover" width="100%"/>
<p align="center"><em><b>ExoMars Mission</b></em><br>Multiple design revisions after prototypes became stuck in soft Martian regolith [ESA, 2025]</p>
</td>
</tr>
</table>

#### **Market Need:**

According to the UN Office for Disaster Risk Reduction (2020):
- **300+ natural disasters annually** affect 200M+ people
- **Limited robotic assistance** due to terrain-accessibility issues
- **Critical need** for autonomous, adaptive ground robots in:
  - ğŸš¨ Search & rescue operations
  - ğŸŒ Planetary exploration
  - ğŸ­ Industrial inspection
  - âš ï¸ Hazardous environment navigation

### Our Solution

This project presents a **unified simulation-based framework** enabling autonomous navigation and real-time morphological adaptation through:

âœ… **Bio-inspired rhythmic control** (Hybrid CPG networks)  
âœ… **Adaptive learning** (PPO-based reinforcement learning)  
âœ… **Environmental perception** (SLAM-based mapping)  
âœ… **Intelligent planning** (A* global + DWA local)  
âœ… **Dynamic reconfiguration** (Terrain-aware morphology switching)  
âœ… **Robust generalization** (Domain randomization)

---

## âš¡ Key Features

### ğŸ§¬ **Hybrid CPG-RL Control**
- Combines Matsuoka + Hopf oscillators for biologically plausible gaits
- PPO agent modulates CPG parameters for terrain adaptation
- **30% faster convergence** vs. naive reward approaches

### ğŸ—ºï¸ **Perception-Driven Navigation**
- Real-time SLAM with depth sensor and IMU fusion
- A* global path planning + DWA local trajectory control
- **84.3% mapping accuracy** in complex environments

### ğŸ¦ **Autonomous Morphology Adaptation**
- 4 discrete modes: Crawler, Walker, Spreader, High-Step
- Terrain-aware switching based on obstacle height, corridor width, roughness
- **22% reduction in pose variance** (stability improvement)

### ğŸ¯ **Performance Metrics**
| Metric | Improvement |
|--------|-------------|
| **Task Success Rate** | 92% (vs 68% baseline) |
| **Cost of Transport** | â†“ 15% |
| **Pose Stability** | â†“ 22% variance |
| **Path Efficiency** | â†‘ 9-17% |

### ğŸ”„ **Robust Generalization**
- Annealed domain randomization schedule
- Â±10% friction, Â±5% restitution, Â±15% compliance variation
- **25% improvement** in terrain traversal under perturbations

---

## ğŸ—ï¸ System Architecture

<p align="center">
  <img src="assets/figures/integrated_framework.png" alt="System Architecture" width="900"/>
  <br>
  <em>Figure 4: Integrated simulation-based framework for autonomous morphological adaptation</em>
</p>

### Module Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AUTONOMY PIPELINE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Sensors  â”‚â”€â”€â”€â–¶â”‚   SLAM   â”‚â”€â”€â”€â–¶â”‚   Planning   â”‚          â”‚
â”‚  â”‚ (Depth,  â”‚    â”‚ (Point   â”‚    â”‚  â€¢ A* Global â”‚          â”‚
â”‚  â”‚  IMU)    â”‚    â”‚  Cloud,  â”‚    â”‚  â€¢ DWA Local â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   Grid)  â”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚                   â”‚
â”‚                                          â”‚                   â”‚
â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚                       â”‚  Morphology Planner        â”‚        â”‚
â”‚                       â”‚  â€¢ Terrain Classification  â”‚        â”‚
â”‚                       â”‚  â€¢ Mode Selection Logic    â”‚        â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                  â”‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚            Hybrid CPG-RL Controller                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â”‚  â”‚ CPG Network â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  PPO Agent   â”‚          â”‚  â”‚
â”‚  â”‚  â”‚ (Matsuoka + â”‚          â”‚ (Modulation) â”‚          â”‚  â”‚
â”‚  â”‚  â”‚    Hopf)    â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                               â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                    â”‚  PyBullet Sim      â”‚                   â”‚
â”‚                    â”‚  (Torque Control)  â”‚                   â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

#### 1ï¸âƒ£ **CPG Subsystem**
- **Matsuoka oscillators**: Neuron-inspired adaptation dynamics
- **Hopf oscillators**: Stable limit-cycle generation
- **Hybrid coupling**: Hopf modulates Matsuoka tonic input
- **Output**: Phase-coordinated joint trajectories

#### 2ï¸âƒ£ **RL Subsystem**
- **Algorithm**: Proximal Policy Optimization (PPO)
- **Observations**: Joint states, body pose, oscillator phases
- **Actions**: CPG parameter modulation (scale, offset)
- **Reward**: Multi-objective (forward progress, energy, jerk)

#### 3ï¸âƒ£ **SLAM Module**
- **Inputs**: Depth camera (640Ã—480), IMU (100Hz)
- **Processing**: Point cloud â†’ RANSAC ground removal â†’ Voxel filter
- **Output**: 2D occupancy grid (0.05m resolution)
- **Update Rate**: 10Hz

#### 4ï¸âƒ£ **Planning Layer**
- **Global**: A* with Euclidean heuristic + obstacle inflation
- **Local**: Dynamic Window Approach (DWA) with clearance scoring
- **Integration**: Real-time waypoint tracking

#### 5ï¸âƒ£ **Morphology Planner**
- **Inputs**: Terrain features (elevation Ïƒ, corridor width, obstacle height)
- **Logic**: Rule-based classifier â†’ mode selection
- **Execution**: Joint-space interpolation (0.5s transition time)

<p align="center">
  <img src="assets/figures/autonomy_loop.png" alt="Perception-Action Loop" width="700"/>
  <br>
  <em>Figure 10: Integrated perception-action control loop</em>
</p>

---

## ğŸŒ Simulation Environment

### PyBullet Configuration

<table>
<tr>
<td width="50%">
<img src="assets/figures/urdf_model_pybullet.png" alt="URDF in PyBullet" width="100%"/>
<p align="center"><em><b>Figure 11:</b> Origaker URDF model in PyBullet</em></p>
</td>
<td width="50%">

**Simulation Parameters:**
- **Physics Engine**: PyBullet 3.2.5
- **Time Step**: 1ms (1000 Hz)
- **Gravity**: -9.81 m/sÂ²
- **Control Mode**: Torque-based
- **Solver**: Featherstone algorithm
- **Contact Model**: Soft constraints

**Model Specifications:**
- **DOF**: 12 (3 per leg)
- **Total Mass**: 8.2 kg
- **Base Dimensions**: 350Ã—250Ã—120 mm
- **Leg Length**: 280 mm
</td>
</tr>
</table>

### Dynamics Validation

<p align="center">
  <img src="assets/figures/dynamics_sanity_check.png" alt="Dynamics Validation" width="900"/>
  <br>
  <em>Figure 12: URDF model validation - Link mass and inertia tensor comparison against CAD reference</em>
</p>

**Validation Process:**
1. âœ… Extract mass/inertia from `getDynamicsInfo()`
2. âœ… Compare with CAD specifications
3. âœ… Enforce <10% deviation threshold
4. âœ… Correct URDF `<inertial>` tags if needed

### Domain Randomization Schedule

The annealed randomization schedule ensures robust policy generalization:
```python
r_t = r_init * (1 - t/T) + r_final * (t/T)
```

Where:
- `r_t`: Randomized parameter at step t
- `r_init`: Initial perturbation range (wide)
- `r_final`: Final range (nominal)
- `T`: Total training steps (1M)

**Randomized Parameters:**
| Parameter | Initial Range | Final Range |
|-----------|---------------|-------------|
| Friction | Â±10% | Â±2% |
| Restitution | Â±5% | Â±1% |
| Link Mass | Â±8% | Â±2% |
| Terrain Slope | Â±15Â° | Â±5Â° |
| Sensor Latency | 0-50ms | 0-10ms |

---

## ğŸ§¬ Hybrid CPG Architecture

### Mathematical Foundation

<p align="center">
  <img src="assets/figures/oscillator_equations.png" alt="CPG Equations" width="700"/>
</p>

#### **Matsuoka Oscillator**

Six coupled first-order ODEs representing mutual inhibition and adaptation:
```
áº‹áµ¢ = -xáµ¢ - wáµ¢â±¼yâ±¼ - Î²váµ¢ + uáµ¢    (membrane potential)
vÌ‡áµ¢ = -váµ¢ + yáµ¢                  (adaptation state)
yáµ¢ = max(0, xáµ¢)                (firing rate)
```

**Parameters:**
- `wáµ¢â±¼`: Inhibitory connection weight
- `Î²`: Adaptation gain
- `uáµ¢`: External tonic input â† **Hopf modulates this**

#### **Hopf Oscillator**

Two-dimensional system with stable limit cycle:
```
áº‹ = (Î¼ - xÂ² - yÂ²)x - Ï‰y    (polar dynamics)
áº = (Î¼ - xÂ² - yÂ²)y + Ï‰x
```

**Parameters:**
- `Î¼`: Amplitude control
- `Ï‰`: Angular frequency

### Phase Portrait Analysis

<p align="center">
  <img src="assets/figures/oscillator_comparison.png" alt="Oscillator Phase Portraits" width="900"/>
  <br>
  <em>Figure 6: Comparative phase portraits - Hopf (circular limit cycle), Matsuoka (convergent), and hybrid Î±-interpolations</em>
</p>

**Key Observations:**
- **Hopf**: Perfect circular limit cycle â†’ stable rhythms
- **Matsuoka**: Fixed-point attractor â†’ adaptive bursting
- **Hybrid Î±=0.3**: Slight spiral convergence (more Hopf-like)
- **Hybrid Î±=0.7**: Straight trajectories (more Matsuoka-like)

### Coupling Mechanism
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       modulation      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Hopf     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Matsuoka   â”‚
â”‚  Oscillator â”‚      (tonic input)    â”‚  Oscillator  â”‚
â”‚   (Î¼, Ï‰)    â”‚                       â”‚  (w, Î², u)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                      â”‚
       â”‚                                      â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                   Phase-coordinated
                   joint trajectories
```

### Parameter Optimization

**Grid Search Strategy:**
- **Search Space**: 1000+ parameter combinations
- **Biological Seeding**: Based on quadruped gait data [Alexander, 2003]
- **Objective**: Pareto-optimal (energy, stability)
- **Storage**: JSON gait library for runtime retrieval

**Optimized Parameter Ranges:**
| Parameter | Range | Selected |
|-----------|-------|----------|
| Matsuoka Î² | 0.5-2.5 | 1.2 |
| Matsuoka wáµ¢â±¼ | 1.0-5.0 | 2.8 |
| Hopf Î¼ | 0.1-1.0 | 0.5 |
| Hopf Ï‰ | 1.0-10.0 | 4.2 |
| Coupling Î± | 0.0-1.0 | 0.6 |

---

## ğŸ¤– Reinforcement Learning Framework

### PPO Architecture

<p align="center">
  <img src="assets/figures/rl_training_loop.png" alt="RL Training Loop" width="800"/>
  <br>
  <em>Figure 7: Adaptive hybrid RL-CPG control architecture</em>
</p>

**Network Structure:**
```
Observations (36-dim)
      â”‚
      â”œâ”€ Joint positions (12)
      â”œâ”€ Joint velocities (12)
      â”œâ”€ Base pose (6: x,y,z,roll,pitch,yaw)
      â”œâ”€ CPG phases (4: one per leg)
      â””â”€ Terrain features (2: slope, roughness)
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Actor Network  â”‚  256â†’256 (ReLU)
â”‚  (Policy Ï€)     â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Actions (8-dim)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 - CPG scale (4)
                                    - CPG offset (4)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Critic Network  â”‚  256â†’256 (ReLU)
â”‚  (Value V)      â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ State Value (1-dim)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Reward Function Design

Multi-objective reward shaping balances speed, efficiency, and smoothness:
```python
R = wâ‚Â·Î”x - wâ‚‚Â·âˆ‘(Ï„áµ¢Â·qÌ‡áµ¢) - wâ‚ƒÂ·â€–qÌˆâ€–â‚‚
    â†‘         â†‘            â†‘
  Progress  Energy      Jerk
            Cost      Penalty
```

<p align="center">
  <img src="assets/figures/reward_decomposition.png" alt="Reward Components" width="800"/>
  <br>
  <em>Figure 14: Reward component analysis over full gait cycle</em>
</p>

**Component Analysis:**
| Term | Weight | Purpose | Impact |
|------|--------|---------|--------|
| Forward Progress (Î”x) | wâ‚=1.0 | Encourage locomotion | Primary drive |
| Energy Cost (Ï„Â·qÌ‡) | wâ‚‚=0.01 | Minimize power | 15% COT reduction |
| Jerk Penalty (â€–qÌˆâ€–â‚‚) | wâ‚ƒ=0.005 | Smooth motion | 22% stability â†‘ |

### Training Configuration

**Hyperparameters:**
```yaml
Algorithm: PPO
Total Timesteps: 1,000,000
Learning Rate: 3e-4 (linear decay)
Batch Size: 64
n_epochs: 10
Clip Range: 0.3 â†’ 0.1 (annealed)
GAE Lambda: 0.95
Discount (Î³): 0.99
Value Coef: 0.5
Entropy Coef: 0.01
Max Grad Norm: 0.5
```

**Hardware:**
- Platform: Windows 11, Intel i7, 16GB RAM
- Training Time: ~18 hours
- Checkpoint Interval: Every 20k steps

### Learning Curves

<p align="center">
  <img src="assets/figures/training_curves.png" alt="Training Progress" width="900"/>
</p>

**Key Milestones:**
- **100k steps**: Basic forward locomotion acquired
- **300k steps**: Energy-efficient gait emerges
- **500k steps**: Stable morphology transitions
- **1M steps**: Convergence with 30% improvement vs. baseline

---

## ğŸ—ºï¸ SLAM & Planning Pipeline

### Perception Architecture

<p align="center">
  <img src="assets/figures/slam_pipeline.png" alt="SLAM Architecture" width="900"/>
  <br>
  <em>Figure 8: SLAM system - Front-end and back-end processing</em>
</p>

#### **Data Flow:**
```
Depth Camera (640Ã—480, 30Hz)
         â”‚
         â–¼
    Point Cloud
         â”‚
         â–¼
   RANSAC Ground Removal
         â”‚
         â–¼
    Voxel Downsampling
         â”‚
         â–¼
   2D Occupancy Grid (10Hz)
         â”‚
         â”œâ”€â”€â”€â–¶ Global Planner (A*)
         â”‚
         â””â”€â”€â”€â–¶ Local Planner (DWA)
```

### SLAM Visualization

<table>
<tr>
<td width="50%">
<img src="assets/figures/slam_3d_pointcloud.png" alt="3D Point Cloud" width="100%"/>
<p align="center"><em><b>(a)</b> 3D Point Cloud Reconstruction</em></p>
</td>
<td width="50%">
<img src="assets/figures/slam_2d_occupancy.png" alt="2D Occupancy Grid" width="100%"/>
<p align="center"><em><b>(b)</b> 2D Occupancy Grid Map</em></p>
</td>
</tr>
</table>

<p align="center">
  <em>Figure 15: Simulated SLAM system with multi-modal camera input</em>
</p>

### Global Path Planning (A*)

<p align="center">
  <img src="assets/figures/astar_planning.png" alt="A* Planning" width="900"/>
  <br>
  <em>Figure 16: A* global path planning in (a) simple maze and (b) corridor maze environments</em>
</p>

**Algorithm Configuration:**
- **Heuristic**: Euclidean distance
- **Obstacle Inflation**: 0.15m radius
- **Cost Function**: g(n) + h(n)
- **Resolution**: 0.05m grid cells

### Local Trajectory Control (DWA)

**Dynamic Window Approach Parameters:**
```yaml
Velocity Search Space:
  - Linear: [-0.5, 1.0] m/s
  - Angular: [-Ï€/2, Ï€/2] rad/s
  
Sampling:
  - dt: 0.1s
  - prediction_horizon: 1.5s
  - num_samples: 50

Scoring Weights:
  - heading: 0.4
  - clearance: 0.3
  - velocity: 0.3
```

<p align="center">
  <img src="assets/figures/dwa_trajectories.png" alt="DWA Candidates" width="700"/>
  <br>
  <em>Sampled DWA trajectories with clearance-based scoring</em>
</p>

---

## ğŸ¦ Morphology Reconfiguration

### Discrete Locomotion Modes

<p align="center">
  <img src="assets/figures/morphology_modes.png" alt="4 Morphology Modes" width="900"/>
  <br>
  <em>Figure 17: Discrete morphological modes - (a) Crawler, (b) Walker, (c) Spreader, (d) High-Step</em>
</p>

### Mode Specifications

| Mode | Use Case | Joint Config | Energy | Stability |
|------|----------|--------------|--------|-----------|
| **Crawler** | Narrow spaces, low clearance | Legs tucked (30Â° from body) | Low | High |
| **Walker** | Normal terrain, standard gait | Balanced stance (60Â° spread) | Medium | High |
| **Spreader** | Wide obstacles, lateral stability | Wide stance (90Â° spread) | Medium | Very High |
| **High-Step** | Tall obstacles, rough terrain | Extended legs (45Â° elevation) | High | Medium |

### Terrain Classification Logic

**Decision Tree:**
```
Input: Local terrain features
  â”œâ”€ Obstacle Height > 0.12m?
  â”‚    â””â”€ YES â†’ High-Step Mode
  â”‚
  â”œâ”€ Corridor Width < 0.4m?
  â”‚    â””â”€ YES â†’ Crawler Mode
  â”‚
  â”œâ”€ Surface Roughness Ïƒ > 0.08?
  â”‚    â””â”€ YES â†’ Spreader Mode
  â”‚
  â””â”€ ELSE â†’ Walker Mode (default)
```

**Feature Extraction:**
```python
# From SLAM occupancy grid
elevation_variance = np.std(heightmap[local_window])
corridor_width = detect_lateral_clearance(occupancy_grid)
forward_obstacle = max_height_in_path(occupancy_grid, lookahead=1.0m)
```

### Mode Switching Timeline

<p align="center">
  <img src="assets/figures/morphology_timeline.png" alt="Mode Timeline" width="900"/>
  <br>
  <em>Figure 18: Origaker morphology timeline over 40s navigation sequence</em>
</p>

**Transition Statistics:**
- **Total Transitions**: 8 over 40s (0.2 trans/s)
- **Most Frequent**: Walker â†” Spreader (stable terrain)
- **Strategic**: High-Step used in 2 short bursts (energy-intensive)
- **Smooth**: Zero failed transitions (kinematic continuity maintained)

### Transition Implementation

**Joint-Space Interpolation:**
```python
def interpolate_morphology(current_config, target_config, duration=0.5):
    """
    Smooth transition between morphologies using cubic interpolation
    """
    t = np.linspace(0, duration, num_steps)
    interpolated_angles = []
    
    for joint_idx in range(12):
        q_start = current_config[joint_idx]
        q_end = target_config[joint_idx]
        
        # Cubic polynomial ensures smooth velocity profile
        q_t = cubic_interpolate(q_start, q_end, t)
        interpolated_angles.append(q_t)
    
    return interpolated_angles
```

**Safety Constraints:**
- **Transition Time**: 0.5s (prevents dynamic instability)
- **Max Angular Velocity**: 2.0 rad/s
- **Kinematic Limits**: Joint angles within [âˆ’Ï€, Ï€]

---

## ğŸ“Š Results

### Performance Metrics Summary

<p align="center">
  <img src="assets/figures/kpi_comparison_table.png" alt="KPI Table" width="700"/>
  <br>
  <em>Table 4: Controller performance comparison across key metrics</em>
</p>

#### **Quantitative Improvements:**

| Metric | Scripted CPG | PPO-Only | **Hybrid PPO-CPG** | Improvement |
|--------|--------------|----------|-------------------|-------------|
| **Cost of Transport â†“** | 2.1 | 1.8 | **1.6** | **24% â†“** |
| **Jerk Index â†“** | 1.03 | 0.71 | **0.45** | **56% â†“** |
| **Slip Ratio â†“** | 0.21 | 0.13 | **0.09** | **57% â†“** |
| **Tracking Error â†“** | 0.12 m | 0.08 m | **0.05 m** | **58% â†“** |
| **Recovery Time â†“** | 1.8 s | 1.2 s | **0.8 s** | **56% â†“** |

### Success Rate Analysis

<p align="center">
  <img src="assets/figures/success_rate_chart.png" alt="Success Rates" width="600"/>
</p>
```
Full System (Hybrid + SLAM + Morphing):  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 92%
Fixed-Mode CPG Baseline:                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        68%
No SLAM (Oracle Map):                    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       75%
No Domain Randomization:                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      81%
```

**Key Finding**: Integrated system achieves **36% relative improvement** over baseline.

### Energy Efficiency (COT)

<p align="center">
  <img src="assets/figures/cot_bar_chart.png" alt="Cost of Transport" width="700"/>
</p>

**Per-Mode Energy Profile:**
| Mode | Avg. Power (W) | Duration (s) | COT |
|------|----------------|--------------|-----|
| Crawler | 8.2 | 12.5 | 1.42 |
| Walker | 10.5 | 18.0 | 1.55 |
| Spreader | 11.8 | 6.5 | 1.68 |
| High-Step | **15.3** | 3.0 | **2.12** |

**Insight**: Strategic mode selection minimizes High-Step usage (high energy) to critical moments.

### Stability Analysis

<p align="center">
  <img src="assets/figures/stability_plot.png" alt="Pose Stability" width="900"/>
</p>

**Pose Variance (Roll/Pitch):**
- **Full System**: Ïƒ = 0.08 rad
- **Fixed-Mode**: Ïƒ = 0.14 rad
- **Improvement**: **43% reduction** in pose instability

### Ablation Study Heatmap

<p align="center">
  <img src="assets/figures/ablation_heatmap.png" alt="Ablation Study" width="800"/>
  <br>
  <em>Component contribution analysis across 5 terrain types</em>
</p>

**Key Contributions:**
| Component Removed | Success Rate â†“ | COT â†‘ | Explanation |
|-------------------|---------------|-------|-------------|
| SLAM | -17% | +12% | Blind navigation fails obstacle avoidance |
| Morphology Switching | -14% | +8% | Fixed configuration limits versatility |
| Domain Randomization | -11% | +6% | Overfitting to training conditions |
| Hybrid CPG | -9% | +15% | Pure RL lacks rhythmic stability |

### Trajectory Following Performance

<p align="center">
  <img src="assets/figures/trajectory_following.png" alt="Path Tracking" width="900"/>
</p>

**Metrics:**
- **Path Deviation**: Mean = 0.05m, Max = 0.12m
- **Goal Reach Accuracy**: 0.03m (within tolerance)
- **Completion Time**: 38.2s (vs. 45.1s baseline)

### Integrated Dashboard

<p align="center">
  <img src="assets/figures/autonomous_dashboard.png" alt="System Dashboard" width="1000"/>
  <br>
  <em>Figure 19: Real-time autonomous navigation system visualization</em>
</p>

**Dashboard Components:**
1. **SLAM Mapping**: 84.3% coverage, real-time point cloud
2. **Terrain Classification**: Confidence levels per region
3. **Morphology Distribution**: Mode usage histogram
4. **Navigation Trajectory**: Planned vs. executed path
5. **PPO Action Selection**: Policy output distribution
6. **Performance Metrics**: Live KPI monitoring

---

## ğŸ¬ Demonstrations

### 1. Hybrid CPG-RL Locomotion

<p align="center">
  <img src="demos/gait_locomotion.gif" alt="Gait Demo" width="600"/>
  <br>
  <em><b>Smooth, energy-efficient trot gait</b> generated by hybrid CPG-RL controller</em>
</p>

[ğŸ“¹ **Full Video (MP4)**](demos/gait_locomotion.mp4) | Duration: 0:30

---

### 2. Autonomous Morphology Switching

<p align="center">
  <img src="demos/morphology_switching.gif" alt="Morphology Demo" width="600"/>
  <br>
  <em><b>Real-time adaptation:</b> Walker â†’ High-Step (obstacle) â†’ Crawler (narrow passage)</em>
</p>

[ğŸ“¹ **Full Video (MP4)**](demos/morphology_switching.mp4) | Duration: 0:45

---

### 3. SLAM Reconstruction

<p align="center">
  <img src="demos/slam_reconstruction.gif" alt="SLAM Demo" width="600"/>
  <br>
  <em><b>Live mapping:</b> Depth sensor â†’ Point cloud â†’ Occupancy grid</em>
</p>

[ğŸ“¹ **Full Video (MP4)**](demos/slam_reconstruction.mp4) | Duration: 0:40

---

### 4. Maze Navigation (Full Pipeline)

<p align="center">
  <img src="demos/maze_navigation.gif" alt="Maze Demo" width="600"/>
  <br>
  <em><b>Complete autonomy:</b> SLAM â†’ A* planning â†’ DWA control â†’ Goal reach</em>
</p>

[ğŸ“¹ **Full Video (MP4)**](demos/maze_navigation.mp4) | Duration: 1:20

---

### 5. Domain Randomization Robustness

<p align="center">
  <img src="demos/domain_randomization.gif" alt="Robustness Demo" width="600"/>
  <br>
  <em><b>Generalization test:</b> Varying friction, slopes, masses - zero retraining</em>
</p>

[ğŸ“¹ **Full Video (MP4)**](demos/domain_randomization.mp4) | Duration: 1:00

---

## ğŸš€ Installation

### Prerequisites
```bash
Python >= 3.8
CUDA 11.7+ (optional, for GPU-accelerated training)
```

### Step 1: Clone Repository
```bash
git clone https://github.com/Degas01/origaker_sources.git
cd origaker_sources
```

### Step 2: Create Virtual Environment
```bash
# Using venv
python -m venv origaker_env
source origaker_env/bin/activate  # Linux/Mac
origaker_env\Scripts\activate     # Windows

# Or using conda
conda create -n origaker python=3.8
conda activate origaker
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

**Key Dependencies:**
```txt
pybullet==3.2.5
stable-baselines3==2.0.0
torch==2.0.1
numpy==1.24.3
scipy==1.10.1
matplotlib==3.7.1
opencv-python==4.7.0
open3d==0.17.0
```

### Step 4: Verify Installation
```bash
python scripts/smoke_test.py
```

Expected output:
```
âœ“ PyBullet initialized
âœ“ Origaker URDF loaded (12 joints)
âœ“ Torque control enabled
âœ“ Smoke test passed: Simulation stable
```

---

## ğŸ’» Usage

### Quick Start: Pre-trained Model Demo
```bash
python demo.py --mode full --terrain maze --gui
```

**Arguments:**
- `--mode`: `full` | `cpg_only` | `rl_only` | `fixed`
- `--terrain`: `flat` | `maze` | `slopes` | `obstacles` | `mixed`
- `--gui`: Launch PyBullet GUI (default: headless)

### Training from Scratch

#### 1. Train PPO Agent
```bash
python train.py \
  --total-timesteps 1000000 \
  --save-freq 20000 \
  --log-dir logs/ \
  --model-save-path models/ppo_origaker \
  --domain-randomization
```

**Monitor Training:**
```bash
tensorboard --logdir=logs/
```

#### 2. Evaluate Trained Policy
```bash
python evaluate.py \
  --model models/ppo_origaker_best.zip \
  --num-episodes 50 \
  --render
```

### Custom Terrain Generation
```bash
python scripts/generate_terrain.py \
  --type maze \
  --complexity 0.7 \
  --size 10x10 \
  --obstacles 15 \
  --save-path terrains/custom_maze.urdf
```

### SLAM Visualization
```bash
python scripts/visualize_slam.py \
  --replay-log logs/slam_episode_042.pkl \
  --show-pointcloud \
  --export-video
```

### Morphology Mode Testing
```bash
python scripts/test_morphology.py \
  --modes crawler walker spreader high_step \
  --transitions-only \
  --save-metrics results/morphology_test.csv
```

---

## ğŸ“ Project Structure
```
origaker_sources/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    â† You are here
â”œâ”€â”€ ğŸ“„ requirements.txt             â† Python dependencies
â”œâ”€â”€ ğŸ“„ LICENSE                      â† MIT License
â”‚
â”œâ”€â”€ ğŸ“‚ assets/                      â† Media assets
â”‚   â”œâ”€â”€ figures/                    â† Paper figures
â”‚   â”œâ”€â”€ demos/                      â† GIFs and videos
â”‚   â””â”€â”€ models/                     â† 3D models (URDF, meshes)
â”‚
â”œâ”€â”€ ğŸ“‚ origaker_urdf/               â† Robot model files
â”‚   â”œâ”€â”€ origaker.urdf               â† Main URDF description
â”‚   â”œâ”€â”€ meshes/                     â† STL collision/visual meshes
â”‚   â””â”€â”€ config/                     â† Joint limits, calibration
â”‚
â”œâ”€â”€ ğŸ“‚ src/                         â† Source code
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ cpg_network.py          â† Hybrid Matsuoka+Hopf CPGs
â”‚   â”‚   â”œâ”€â”€ rl_agent.py             â† PPO policy wrapper
â”‚   â”‚   â””â”€â”€ torque_controller.py    â† Low-level joint control
â”‚   â”‚
â”‚   â”œâ”€â”€ perception/
â”‚   â”‚   â”œâ”€â”€ slam.py                 â† Point cloud SLAM
â”‚   â”‚   â””â”€â”€ terrain_classifier.py   â† Feature extraction
â”‚   â”‚
â”‚   â”œâ”€â”€ planning/
â”‚   â”‚   â”œâ”€â”€ astar_planner.py        â† Global path planning
â”‚   â”‚   â””â”€â”€ dwa_controller.py       â† Local trajectory control
â”‚   â”‚
â”‚   â”œâ”€â”€ morphology/
â”‚   â”‚   â”œâ”€â”€ mode_selector.py        â† Terrain-aware switching
â”‚   â”‚   â””â”€â”€ interpolator.py         â† Smooth joint transitions
â”‚   â”‚
â”‚   â””â”€â”€ simulation/
â”‚       â”œâ”€â”€ environment.py          â† PyBullet Gym env
â”‚       â”œâ”€â”€ domain_randomizer.py    â† Parameter perturbations
â”‚       â””â”€â”€ terrain_generator.py    â† Procedural terrains
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                     â† Utility scripts
â”‚   â”œâ”€â”€ train.py                    â† PPO training pipeline
â”‚   â”œâ”€â”€ evaluate.py                 â† Model evaluation
â”‚   â”œâ”€â”€ demo.py                     â† Interactive demo
â”‚   â”œâ”€â”€ smoke_test.py               â† Basic sanity checks
â”‚   â”œâ”€â”€ visualize_slam.py           â† SLAM replay tool
â”‚   â””â”€â”€ generate_terrain.py         â† Custom terrain creator
â”‚
â”œâ”€â”€ ğŸ“‚ configs/                     â† Configuration files
â”‚   â”œâ”€â”€ training_config.yaml        â† PPO hyperparameters
â”‚   â”œâ”€â”€ cpg_params.json             â† Optimized CPG library
â”‚   â””â”€â”€ morphology_modes.json       â† Joint configurations
â”‚
â”œâ”€â”€ ğŸ“‚ logs/                        â† Training logs (TensorBoard)
â”œâ”€â”€ ğŸ“‚ models/                      â† Saved model checkpoints
â”œâ”€â”€ ğŸ“‚ results/                     â† Evaluation metrics (CSV)
â”œâ”€â”€ ğŸ“‚ tests/                       â† Unit tests
â”‚
â””â”€â”€ ğŸ“‚ docs/                        â† Documentation
    â”œâ”€â”€ PAPER.pdf                   â† Full MSc thesis
    â”œâ”€â”€ ARCHITECTURE.md             â† System design details
    â”œâ”€â”€ API_REFERENCE.md            â† Code documentation
    â””â”€â”€ TUTORIAL.ipynb              â† Jupyter tutorial notebook
```

---

## ğŸ“– Citation

If you use this work in your research, please cite:
```bibtex
@mastersthesis{masone2025origaker,
  title={Enhancing Metamorphic Legged Robot Locomotion Using Machine Learning and Nature-Inspired Design},
  author={Masone, Giacomo Demetrio},
  year={2025},
  school={King's College London},
  type={MSc Thesis},
  department={Engineering Department},
  supervisor={Spyrakos-Papastavridis, Emmanouil}
}
```

**Related Publications:**
```bibtex
@article{tang2022origaker,
  title={Origaker: A Novel Multi-Mimicry Quadruped Robot Based on a Metamorphic Mechanism},
  author={Tang, Z. and Wang, K. and Spyrakos-Papastavridis, E. and Dai, J.S.},
  journal={Journal of Mechanisms and Robotics},
  volume={14},
  number={6},
  year={2022}
}
```

---

## ğŸ”® Future Work

### Short-Term Extensions

#### 1. **Sim-to-Real Transfer**
- [ ] System identification on physical Origaker platform
- [ ] Adaptive domain randomization refinement
- [ ] Real-time sensor noise characterization
- [ ] Contact dynamics calibration
- [ ] Power consumption validation

#### 2. **Vision-Based SLAM**
- [ ] RGB-D integration (currently depth-only)
- [ ] ORB feature tracking for loop closure
- [ ] Semantic segmentation for terrain classification
- [ ] Multi-modal sensor fusion (LiDAR + camera)

#### 3. **Continuous Morphology Optimization**
- [ ] Replace discrete modes with continuous joint-space optimization
- [ ] Online trajectory optimization (e.g., iLQR, DDP)
- [ ] Learned mode selection via RL (meta-learning)
- [ ] Energy-optimal configuration search

### Mid-Term Goals

#### 4. **RL-Based Morphology Switching**
- [ ] Train hierarchical policy: meta-controller selects modes
- [ ] Multi-task learning across terrain types
- [ ] Transfer learning from simulation clusters
- [ ] Curriculum learning for progressively harder terrains

#### 5. **Multi-Terrain Generalization**
- [ ] Expand test suite: sand, mud, ice, gravel, vegetation
- [ ] Deformable terrain simulation (e.g., Taichi-MPM)
- [ ] Dynamic obstacles and moving platforms
- [ ] Outdoor field trials (unstructured environments)

#### 6. **Robustness Enhancements**
- [ ] Failure recovery strategies (e.g., self-righting)
- [ ] Fault-tolerant control (leg damage scenarios)
- [ ] Battery-aware planning (energy-constrained missions)
- [ ] Communication loss resilience

### Long-Term Vision

#### 7. **Multi-Agent Collaboration**
- [ ] Fleet coordination for search & rescue
- [ ] Distributed SLAM and map merging
- [ ] Task allocation and role specialization
- [ ] Swarm behavior emergence

#### 8. **Real-World Deployment**
- [ ] King's College campus autonomous navigation trials
- [ ] Industrial inspection applications (nuclear, offshore)
- [ ] Disaster response scenario testing (UK Fire Service collaboration)
- [ ] Planetary analog missions (ESA partnership)

#### 9. **Open-Source Community**
- [ ] ROS2 integration for broader compatibility
- [ ] Web-based simulation interface (JavaScript/WebAssembly)
- [ ] Benchmarking suite for locomotion research
- [ ] Educational modules for university courses

---

## ğŸ™ Acknowledgements

This research was conducted at **King's College London** as part of the MSc Robotics program.

### Supervision & Mentorship
- **Prof./Dr. Emmanouil Spyrakos-Papastavridis** â€“ Primary Supervisor  
  *For invaluable guidance, expertise, and unwavering support throughout this project*

- **Dr. Taisir Elgorashi** â€“ Degree Committee Member  
  *For insightful feedback and scholarly input that enriched this work*

### Academic Community
- **MSc Robotics Cohort 2024-2025** â€“ Course Colleagues  
  *For collaborative discussions, moral support, and friendship*

- **King's College London Engineering Department**  
  *For providing world-class resources, facilities, and academic environment*

### Technical Foundations
This project builds upon foundational work:
- **Origaker Platform** â€“ Tang et al. (2022)
- **Stable-Baselines3** â€“ Raffin et al.
- **PyBullet** â€“ Erwin Coumans & team

### Personal Support
- **My Parents** â€“ *Driving force behind every achievement*  
  *For their unconditional love, sacrifice, and belief in my potential*

---

## ğŸ“œ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

### Third-Party Licenses
- PyBullet: Zlib License
- Stable-Baselines3: MIT License
- Open3D: MIT License

---

## ğŸ“¬ Contact

**Giacomo Demetrio Masone**  
MSc Robotics, King's College London  

ğŸ“§ Email: [your.email@kcl.ac.uk](mailto:your.email@kcl.ac.uk)  
ğŸ”— LinkedIn: [linkedin.com/in/your-profile](https://linkedin.com/in/your-profile)  
ğŸ™ GitHub: [@Degas01](https://github.com/Degas01)  
ğŸ“ Google Scholar: [Your Scholar Profile](https://scholar.google.com)

---

<p align="center">
  <img src="assets/figures/kcl_logo.png" alt="King's College London" height="60"/>
  &nbsp;&nbsp;&nbsp;&nbsp;
  <img src="assets/figures/robotics_lab_logo.png" alt="Robotics Lab" height="60"/>
</p>

<p align="center">
  <sub>Made with â¤ï¸ and a lot of â˜• in London, 2025</sub>
</p>

---

## ğŸ“Š Repository Statistics

![GitHub stars](https://img.shields.io/github/stars/Degas01/origaker_sources?style=social)
![GitHub forks](https://img.shields.io/github/forks/Degas01/origaker_sources?style=social)
![GitHub watchers](https://img.shields.io/github/watchers/Degas01/origaker_sources?style=social)
![GitHub commit activity](https://img.shields.io/github/commit-activity/m/Degas01/origaker_sources)
![GitHub last commit](https://img.shields.io/github/last-commit/Degas01/origaker_sources)
![GitHub repo size](https://img.shields.io/github/repo-size/Degas01/origaker_sources)

<p align="center">
  <strong>â­ Star this repository if you found it helpful!</strong>
</p>

---

**[â¬† Back to Top](#-origaker-adaptive-metamorphic-legged-robot-locomotion)**










